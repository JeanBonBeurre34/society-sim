# ğŸ§  Society Simulation â€” Interactive AI World

An **interactive, learning-based simulation of a miniature society**, where multiple AI agents coexist, compete, and cooperate inside a shared environment.  
Each agent is driven by an independent **Actorâ€“Critic reinforcement learning model** that adapts behavior through reward signals â€” creating emergent social patterns like cooperation, trade, and conflict.

This project runs best inside **Jupyter notebooks**, where you can visualize both the evolving **social relationships** and **geographical world** in real time, then replay the simulation step by step.

---

## ğŸš€ Features

### ğŸŒ World Engine
- 2D **cellular grid** representing the environment.
- Each cell contains a renewable resource (`stock`) that regenerates at a configurable rate.
- Agents can move between cells, gather resources, or interact with one another.
- Resources are limited, encouraging both competition and cooperation.

### ğŸ§© AI Agents
- Each agent is powered by a small **Actorâ€“Critic neural network** (see `agent_brain.py`).
- The network learns from experience using a replay buffer and reward feedback.
- Agents perceive local state information:
  - Their **wealth**
  - Their **reputation**
  - The **average resources** in their current cell
  - The **number of other agents** nearby
- Available actions:
  ```
  move, gather, help, donate, trade, steal
  ```

### ğŸ“Š Live Visualization (Jupyter)
The simulation visualizes three synchronized panels:
1. **Social Graph (top-left):**  
   - Nodes represent agents (size = wealth, color = points).  
   - Edges represent interactions:  
     - ğŸŸ© **Green** = help (cooperation)  
     - ğŸ”µ **Blue** = trade (neutral exchange)  
     - ğŸ”´ **Red** = steal (conflict)
2. **World Map (top-right):**  
   - Shows agentsâ€™ positions on the grid.  
   - Cell color intensity (green) = wealth concentration.  
   - Agents are colored by performance points.
3. **Metrics Over Time (bottom):**  
   - Tracks global statistics across ticks:
     - Average wealth  
     - Average points  
     - Number of cooperative (â€œhelpâ€) edges  
     - Number of conflict (â€œstealâ€) edges  

### ğŸï¸ Replay Timeline
When the simulation finishes, use an **interactive slider** to replay it through time:
- Drag the slider left/right to move between frames.
- Each frame shows the societyâ€™s network, world, and agents at that specific tick.

---

## ğŸ§° Installation

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/yourusername/society-sim.git
cd society-sim
```

### 2ï¸âƒ£ Create a Python environment (optional but recommended)

```bash
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install torch matplotlib networkx ipywidgets
```

Enable Jupyter widgets (for the slider to work):

```bash
jupyter nbextension enable --py widgetsnbextension
```

Alternatively, create a `requirements.txt`:

```
torch
matplotlib
networkx
ipywidgets
```

and install with:

```bash
pip install -r requirements.txt
```

---

## ğŸ§  How to Run the Simulation (Inside Jupyter)

### Start Jupyter

```bash
jupyter lab
```

Then open a new notebook and run:

```python
from society_sim import run_simulation

# Run simulation with 8 agents for 100 ticks
world = run_simulation(agents=8, ticks=100, pause=0.03)
```

Once complete, replay the entire timeline:

```python
world.replay()
```

Youâ€™ll see a **slider** under the plot â€” drag it to move through time, frame by frame ğŸï¸.

---

## ğŸ§© Interpreting the Visualization

### ğŸ•¸ï¸ Social Graph
| Visual Element | Meaning |
|-----------------|----------|
| Node size | Agentâ€™s wealth |
| Node color | Agentâ€™s performance (points) |
| ğŸŸ© Green edge | â€œHelpâ€ â€” cooperative interaction |
| ğŸ”µ Blue edge | â€œTradeâ€ â€” neutral, balanced exchange |
| ğŸ”´ Red edge | â€œStealâ€ â€” aggressive/conflict interaction |

> The mix of edge colors reveals the overall tone of the society â€” cooperative or conflict-driven.

---

### ğŸŒ World Map
| Visual Element | Meaning |
|-----------------|----------|
| Grid cell | A geographic zone with renewable resources |
| Green intensity | Average wealth of agents in the cell |
| Colored dots | Agents (color = points, brighter = stronger) |
| Coordinates `(x, y)` | Grid position |

> Agents move, gather, or interact â€” creating wealth clusters and dynamic population flows.

---

### ğŸ“ˆ Society Metrics (Bottom Panel)
| Line | Meaning |
|------|----------|
| ğŸŸ¢ Green | Average wealth of all agents |
| ğŸŸ£ Purple | Average points (performance) |
| ğŸ”µ Blue dashed | Number of â€œhelpâ€ edges (cooperation) |
| ğŸ”´ Red dashed | Number of â€œstealâ€ edges (conflict) |

> Rising green line = growing economy  
> Rising red dashed = conflict increasing  
> Rising blue dashed = cooperation emerging  

---

## âš™ï¸ Configuration and Tuning

You can modify constants in `society_sim.py` or `agent_brain.py` to experiment with different societies.

| Parameter | Description | Default |
|------------|-------------|----------|
| `HELP_REWARD` | Reward for helping others | 4.0 |
| `TRADE_REWARD` | Reward for trading | 2.0 |
| `STEAL_PENALTY` | Penalty for stealing | -6.0 |
| `regen_per_tick` | Resource regeneration speed | 2 |
| `capacity` | Max stock in each cell | 50 |
| `ticks` | Duration of simulation | 100 |

> For example, setting `STEAL_PENALTY=-10` and `HELP_REWARD=6` encourages a more cooperative civilization.

---

## ğŸ§© File Structure

```
society-sim/
â”œâ”€â”€ agent_brain.py     # Reinforcement Learning: Actorâ€“Critic model
â”œâ”€â”€ society_sim.py     # World logic, visualization, replay system
â”œâ”€â”€ requirements.txt   # Python dependencies
â””â”€â”€ README.md          # Project documentation
```

---

## ğŸ”¬ Example Jupyter Workflow

```python
# 1. Import and run
from society_sim import run_simulation
world = run_simulation(agents=10, ticks=80, pause=0.05)

# 2. Replay results
world.replay()

# 3. Access world data programmatically
print("Total ticks:", world.time)
print("Agent 0 wealth:", world.agents[0].wealth)
print("Cooperative edges:", len(world.graph.edge_types["help"]))
```

---

## ğŸ§  How Learning Works

Each agent maintains its own neural network defined in `agent_brain.py`:

- **Actor** â†’ decides which action to take (policy).
- **Critic** â†’ estimates how good the current state is (value function).
- **Replay Buffer** â†’ stores past experiences for stable training.

Agents receive *reward signals* based on their behavior:
- Helping others â†’ positive reward  
- Stealing â†’ penalty  
- Gathering resources â†’ mild reward  

Over many ticks, this feedback drives emergent strategies â€” from pure selfishness to cooperative clusters.

---

## ğŸ§® Mathematical Summary

Let:
- `s_t` = current state  
- `a_t` = action  
- `r_t` = reward  
- `V(s_t)` = critic-estimated value  

Each update minimizes:
```
L = -log Ï€(a_t | s_t) * (r_t + Î³V(s_{t+1}) - V(s_t)) + (r_t + Î³V(s_{t+1}) - V(s_t))Â²
```
where:
- The first term updates the policy (actor).
- The second term trains the critic to predict correct state values.

---

## ğŸ§® Sample Output Metrics (Example Run)

| Tick | Avg Wealth | Avg Points | Help Edges | Steal Edges |
|-------|-------------|-------------|-------------|-------------|
| 0 | 2.1 | 0.0 | 0 | 0 |
| 20 | 5.3 | 2.4 | 10 | 28 |
| 60 | 10.1 | 4.5 | 21 | 55 |
| 100 | 14.8 | 7.2 | 27 | 62 |

Youâ€™ll see this reflected in the line chart â€” society tends to accumulate wealth even under conflict, but cooperation improves overall stability.

---

## ğŸ§  Tips for Exploration

- Increase `ticks` to 500+ and observe long-term equilibria.
- Try fewer agents with high `HELP_REWARD` for utopian behavior.
- Try many agents with low resources for chaotic, competitive dynamics.
- Introduce new policies (like taxation or voting) as extra rules in `World.step()`.

---

## ğŸ’¡ Possible Extensions

âœ… Add a **Gini coefficient** metric to measure inequality.  
âœ… Create **alliances** or **reputation systems** between agents.  
âœ… Introduce **taxation** and **universal income** policies.  
âœ… Export the full metrics history to CSV for analysis in Pandas.  
âœ… Build an **interactive control panel** (buttons for pause/resume).  

---

## ğŸ§  Example: Running in Docker

You can also containerize the project for portability.

**Dockerfile**
```dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY . .
RUN pip install --no-cache-dir torch matplotlib networkx ipywidgets jupyter
EXPOSE 8888
CMD ["jupyter", "lab", "--ip=0.0.0.0", "--no-browser", "--allow-root"]
```

Then build and run:

```bash
docker build -t society-sim .
docker run -p 8888:8888 society-sim
```

Follow the URL shown in the logs to access Jupyter Lab in your browser.

---

## ğŸ“œ License

**MIT License**

You are free to use, modify, and distribute this project for research, education, or creative experiments.  
Attribution is appreciated.

---

## âœ¨ Credits

Developed by **Paul Dubourg**  
Designed for exploratory AI research, social behavior modeling, and interactive visualization in Python.

> â€œA society of learning agents â€” where cooperation, greed, and evolution emerge from code.â€

---

## ğŸ§© Badges

![Python](https://img.shields.io/badge/Python-3.11-blue)
![License: MIT](https://img.shields.io/badge/License-MIT-green)
![Jupyter](https://img.shields.io/badge/Platform-Jupyter-orange)
![RL](https://img.shields.io/badge/Reinforcement-Learning-purple)
